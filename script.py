import pandas as pdfrom sklearn.model_selection import train_test_splitfrom sklearn.ensemble import RandomForestClassifierfrom sklearn.cluster import KMeansimport numpy as npfrom geopy.distance import geodesicimport folium# Load CSV fileprint("Loading data...")data = pd.read_csv('crash_data.csv', low_memory=False)print("Data loaded successfully.")# -------------------- DATA CLEANING --------------------def clean_data(df):    print("Starting data cleaning...")    # Drop duplicates    df = df.drop_duplicates()        # Fill missing numerical values with 0    num_cols = ['NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED',                'NUMBER OF PEDESTRIANS INJURED', 'NUMBER OF PEDESTRIANS KILLED',                'NUMBER OF CYCLIST INJURED', 'NUMBER OF CYCLIST KILLED',                'NUMBER OF MOTORIST INJURED', 'NUMBER OF MOTORIST KILLED']    df[num_cols] = df[num_cols].fillna(0)        # Drop rows where LOCATION (latitude/longitude) is missing or invalid    df = df.dropna(subset=['LATITUDE', 'LONGITUDE'])    df = df[(df['LATITUDE'] != 0) & (df['LONGITUDE'] != 0) & (df['LONGITUDE'] > -180) & (df['LONGITUDE'] < 180)]        # Convert 'CRASH DATE' and 'CRASH TIME' to datetime format    df['CRASH DATETIME'] = pd.to_datetime(df['CRASH DATE'] + ' ' + df['CRASH TIME'], errors='coerce')    df = df.drop(columns=['CRASH DATE', 'CRASH TIME'])        # Ensure contributing factors columns exist and fill missing ones    factor_cols = ['CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING FACTOR VEHICLE 2',                    'CONTRIBUTING FACTOR VEHICLE 3', 'CONTRIBUTING FACTOR VEHICLE 4',                    'CONTRIBUTING FACTOR VEHICLE 5']    for col in factor_cols:        if col not in df.columns:            df[col] = 'Unknown'        else:            df[col] = df[col].fillna('Unknown')        print(f"Data cleaning completed. Number of entries remaining: {len(df)}")    return dfcleaned_data = clean_data(data)print("Cleaned Data:")print(cleaned_data.sample(5))  # Display 5 random rows instead of head()# -------------------- CLASSIFICATION --------------------# Goal: Predict if a crash involves injuries based on contributing factors and location.def classify_crashes(df):    print("Starting classification...")    # Convert contributing factors to numerical values (one-hot encoding)    df_encoded = pd.get_dummies(df, columns=[col for col in df.columns if col.startswith('CONTRIBUTING FACTOR')])        # Define features AFTER encoding    features = ['LATITUDE', 'LONGITUDE'] + [col for col in df_encoded.columns if 'CONTRIBUTING FACTOR' in col]        # Ensure all features exist in the encoded dataframe    X = df_encoded[features]    y = (df['NUMBER OF PERSONS INJURED'] > 0).astype(int)  # Binary target variable        # Align columns in case of mismatch    X = X.loc[:, ~X.columns.duplicated()]        # Split data    print("Splitting data for classification...")    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)        # Train a RandomForestClassifier    print("Training RandomForestClassifier...")    clf = RandomForestClassifier()    clf.fit(X_train, y_train)    print(f"Classification completed. Accuracy: {clf.score(X_test, y_test):.2f}")classify_crashes(cleaned_data)# -------------------- CLUSTERING --------------------# Goal: Identify crash severity hotspots.def cluster_severity_hotspots(df):    print("Starting clustering for crash severity hotspots...")    # Calculate severity score    df['SEVERITY_SCORE'] = (df['NUMBER OF PERSONS INJURED'] + df['NUMBER OF PEDESTRIANS INJURED'] +                            df['NUMBER OF CYCLIST INJURED'] + df['NUMBER OF MOTORIST INJURED'])        # Filter for meaningful clusters (exclude rows with zero severity)    severity_data = df[df['SEVERITY_SCORE'] > 0][['LATITUDE', 'LONGITUDE', 'SEVERITY_SCORE']]        if severity_data.empty:        print("No crashes with injuries to cluster.")        return df    # Normalize severity score for clustering    severity_data['SEVERITY_SCORE'] = (severity_data['SEVERITY_SCORE'] - severity_data['SEVERITY_SCORE'].mean()) / severity_data['SEVERITY_SCORE'].std()    # Use fixed number of clusters    n_clusters = 10    kmeans = KMeans(n_clusters=n_clusters, random_state=42)    print(f"Fitting KMeans with {n_clusters} clusters...")    severity_data['Cluster'] = kmeans.fit_predict(severity_data[['LATITUDE', 'LONGITUDE', 'SEVERITY_SCORE']])    print("Clustering completed. Cluster centers:")    cluster_info = []    for i, center in enumerate(kmeans.cluster_centers_):        print(f"Cluster {i}: Location ({center[0]:.4f}, {center[1]:.4f}), Severity Score: {center[2]:.2f}")        cluster_info.append({            'Cluster': i,            'Latitude': center[0],            'Longitude': center[1],            'Severity_Score': center[2]        })    # Calculate cluster radius    print("Calculating cluster radii...")    max_radius = 50000  # Cap radius at 50 km for visualization clarity    for i in range(n_clusters):        cluster_points = severity_data[severity_data['Cluster'] == i]        distances = cluster_points.apply(lambda row: geodesic((row['LATITUDE'], row['LONGITUDE']),                                                              (kmeans.cluster_centers_[i][0], kmeans.cluster_centers_[i][1])).meters, axis=1)        cluster_radius = min(distances.max(), max_radius) if not distances.empty else 0        cluster_info[i]['Radius_meters'] = cluster_radius        print(f"Cluster {i} radius: {cluster_radius:.2f} meters")    # Merge cluster labels back to the main dataframe    df = df.merge(severity_data[['LATITUDE', 'LONGITUDE', 'Cluster']], on=['LATITUDE', 'LONGITUDE'], how='left')    print("Cluster assignment completed.")    return df, cluster_infoclustered_data, cluster_details = cluster_severity_hotspots(cleaned_data)print("Clustered Data Sample:")print(clustered_data[['LATITUDE', 'LONGITUDE', 'SEVERITY_SCORE', 'Cluster']].dropna().sample(5))print("Cluster Details:")for cluster in cluster_details:    print(cluster)# -------------------- VISUALIZATION --------------------# Plot clusters on a mapdef plot_clusters_on_map(cluster_info):    print("Creating map visualization...")    # Create a base map centered at an approximate location    m = folium.Map(location=[40.7223, -73.9188], zoom_start=12)    # Plot each cluster    for cluster in cluster_info:        # Add a marker for the cluster centroid        folium.Marker(            location=[cluster['Latitude'], cluster['Longitude']],            popup=f"Cluster {cluster['Cluster']}\nSeverity Score: {cluster['Severity_Score']:.2f}\nRadius: {cluster['Radius_meters']:.2f} meters",            icon=folium.Icon(color="red", icon="info-sign")        ).add_to(m)        # Add a circle representing the cluster radius        folium.Circle(            location=[cluster['Latitude'], cluster['Longitude']],            radius=cluster['Radius_meters'],            color='blue',            fill=True,            fill_opacity=0.2        ).add_to(m)    # Save or display the map    m.save("clusters_map.html")    print("Map saved as clusters_map.html")plot_clusters_on_map(cluster_details)